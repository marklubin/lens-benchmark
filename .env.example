# LENS Benchmark — Environment Configuration
# Copy to .env and fill in your values:  cp .env.example .env

# ── LLM Provider ──────────────────────────────────────────────
# Provider: "mock" (no API, deterministic) | "openai" (OpenAI-compatible)
LENS_LLM_PROVIDER=mock

# API key for the chosen provider
# LENS_LLM_API_KEY=sk-...

# Model name (provider-specific)
#   OpenAI:   gpt-4o-mini, gpt-4o
#   DeepSeek: deepseek-chat (V3, non-thinking), deepseek-reasoner (R1, thinking)
# LENS_LLM_MODEL=gpt-4o-mini

# Base URL override — use this for OpenAI-compatible APIs:
#   DeepSeek:   https://api.deepseek.com
#   OpenRouter: https://openrouter.ai/api/v1
#   Local vLLM: http://localhost:8000/v1
# LENS_LLM_API_BASE=

# ── Generation Parameters ─────────────────────────────────────
# LENS_LLM_TEMPERATURE=0.0
# LENS_LLM_SEED=42

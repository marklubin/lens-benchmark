{
  "label": "cascading_failure_01_dx_storage_capacity_020",
  "artifact_type": "distractor_episode",
  "artifact_id": "sha256:ef7061c446f9db73811539008a3623df7e3a81e1ec22c53364178ffc0a406a53",
  "input_ids": [
    "sha256:6cb28686746e7839fd3bed94bcd50530c285310fd7a053289c49cbe7c08d55ba",
    "sha256:8bd255056921270a7048555e132196af832705b4e437017f1abea5378ca40697"
  ],
  "prompt_id": null,
  "model_config": null,
  "created_at": "2026-02-16T03:35:11.918923",
  "content": "## 2026-01-21 Daily Operations Summary\n\n### Endpoint Performance\n- /storage/cluster_capacity: REQUESTS req | p50: 0ms p95: 0ms p99: 0ms | err: 0% (0 errors) | success: 100%\n- /storage/node_utilization: REQUESTS req | p50: 0ms p95: 0ms p99: 0ms | err: 0% (0 errors) | success: 100%\n- /storage/rebalance: REQUESTS req | p50: 0ms p95: 0ms p99: 0ms | err: 0% (0 errors) | success: 100%\n- /storage/compaction: REQUESTS req | p50: 0ms p95: 0ms p99: 0ms | err: 0% (0 errors) | success: 100%\n- /storage/io: REQUESTS req | p50: 0ms p95: 0ms p99: 0ms | err: 0% (0 errors) | success: 100%\n- /storage/storage_efficiency: REQUESTS req | p50: 0ms p95: 0ms p99: 0ms | err: 0% (0 errors) | success: 100%\n- /storage/backup_verification: REQUESTS req | p50: 0ms p95: 0ms p99: 0ms | err: 0% (0 errors) | success: 100%\n- /storage/quota_enforcement: REQUESTS req | p50: 0ms p95: 0ms p99: 0ms | err: 0% (0 errors) | success: 100%\n- /storage/ingest: REQUESTS req | p50: 0ms p95: 0ms p99: 0ms | err: 0% (0 errors) | success: 100%\n- /storage/reliability: REQUESTS req | p50: 0ms p95: 0ms p99: 0ms | err: 0% (0 errors) | success: 100%\n- /storage/metadata: REQUESTS req | p50: 0ms p95: 0ms p99: 0ms | err: 0% (0 errors) | success: 100%\n- /storage/maintenance: REQUESTS req | p50: 0ms p95: 0ms p99: 0ms | err: 0% (0 errors) | success: 100%\n\n### Infrastructure\n- stor-a-20: CPU 78% | Mem 85% | Disk Used 98% | Disk Busy 91% | Conns: N | Net: 8.3/7.4 Mbps\n- stor-b-13: CPU 67% | Mem 76% | Disk Used 96% | Disk Busy 89% | Conns: N | Net: 6.9/6.5 Mbps\n- stor-c-12: CPU 61% | Mem 72% | Disk Used 95% | Disk Busy 88% | Conns: N | Net: 6.3/5.9 Mbps\n- meta-01: CPU 70% | Mem 92% | Disk Used 87% | Disk Busy 73% | Conns: N | Net: 3.7/3.3 Mbps\n\n### Connection Pools\n- pool-main: active 120 | idle 30 | waiting 5 | exhaustion: 2 | max: 150 | avg_wait: 12ms\n- pool-backup: active 45 | idle 20 | waiting 3 | exhaustion: 1 | max: 70 | avg_wait: 8ms\n- pool-io: active 60 | idle 15 | waiting 4 | exhaustion: 0 | max: 80 | avg_wait: 10ms\n\n### CDN & Caching\n- Hit rate: 89.1% | Bandwidth: 4.2 Gbps | Origin requests: 12,340\n\n### Alerts\n- [CRITICAL] disk failure on stor-c-12: replaced and rebuilt in 7.2 hours\n- [WARNING] metadata backlog: 3,600 backlog items\n- [INFO] cache hit rate improved above 89%\n- [WARNING] quota soft limit hits: 28\n- [CRITICAL] disk failures: 1\n- [INFO] scrub errors: 22\n- [WARNING] nodes over 80% utilization: 79\n- [CRITICAL] nodes over 90% utilization: 32\n- [CRITICAL] hottest node utilization: 98.5%\n- [INFO] metadata database size: 1210 GB\n- [INFO] manifest backlog: 3,600\n- [INFO] total tenants: 91\n- [WARNING] tenants over quota: 5\n- [WARNING] quota soft limit hits: 28\n- [CRITICAL] disk rebuilds completed: 1\n- [INFO] last restore RTO: 50 min\n- [INFO] network drops: 16\n- [INFO] audit log size: 85 GB\n\n### Deployments & Changes\n- Completed 13 rebalance jobs, reducing skew index to 1.05 and lowering scrub pressure by spreading hot partitions\n- Disk failure on stor-c-12 replaced and rebuilt in 7.2 hours; monitored for under-replicated objects (none sustained)\n- Metadata throttling and batching reduced manifest backlog from 5.2k to 3.6k; cache hit improved above 89%\n- Quota hard blocks reduced from 5 to 4 after applying ingest caps; processed six quota increase requests with capacity committee review\n\n### Events\n- Completed 13 rebalance jobs, reducing skew index to 1.05 and lowering scrub pressure by spreading hot partitions\n- Disk failure on stor-c-12 replaced and rebuilt in 7.2 hours; watched for any under-replicated objects (none sustained)\n- Metadata throttling and batching reduced manifest backlog from 5.2k to 3.6k; cache hit improved above 89%\n- Quota hard blocks reduced from 5 to 4 after applying ingest caps; processed six quota increase requests with capacity committee review\n\n### On-Call\n- Shift: Ivan B. 5 pages. 10 tickets. Status: Stable; recovery day with improved balance and metadata backlog reduction. Capacity remains constrained; approvals for quota increases are now gated on lifecycle plans.",
  "metadata": {
    "episode_type": "distractor",
    "theme": "storage_capacity",
    "theme_index": 1,
    "local_index": 20,
    "scope_id": "cascading_failure_01",
    "layer_name": "distractor_episodes",
    "layer_level": 2,
    "build_fingerprint": {
      "scheme": "synix:build:v1",
      "digest": "689c0ebfb6278f095d9a8ad2f028d8f17a2bc63888d694033e41477cddc6a8e0",
      "components": {
        "transform": "1db107c0320f12aacae9855d2bf7cfba02d6ff84f017b495964716da701d04b0",
        "inputs": "1a71c817b3637bbe"
      }
    },
    "transform_fingerprint": {
      "scheme": "synix:transform:v2",
      "digest": "1db107c0320f12aacae9855d2bf7cfba02d6ff84f017b495964716da701d04b0",
      "components": {
        "transform_id": "01137a4997b78f86",
        "source": "c42d9c6282d5331f",
        "model": "478abb44e4d92bdf"
      }
    }
  }
}
{
  "label": "cascading_failure_01_dx_storage_capacity_010",
  "artifact_type": "distractor_episode",
  "artifact_id": "sha256:ff30dd8a96059941a0de820b2c08b8655262a95cec5c7afe7fc65465cc85024b",
  "input_ids": [
    "sha256:00449ed9d7f8a3240548c2009abc6e3ccafc743718f92388a22452f2b9699234",
    "sha256:8bd255056921270a7048555e132196af832705b4e437017f1abea5378ca40697"
  ],
  "prompt_id": null,
  "model_config": null,
  "created_at": "2026-02-17T11:57:24.879593",
  "content": "## 2026-01-11 Daily Operations Summary\n\n### Metrics\n#### Cluster Capacity\n- Raw TB Total: 9820\n- Raw TB Used: 7840\n- Raw TB Free: 1980\n- Effective TB Total: 6540\n- Effective TB Used: 5602\n- Effective TB Free: 938\n- Overall Utilization Percentage: 79.8\n\n#### Node Utilization\n- Nodes Total: 120\n- Nodes Over 80% Utilization: 62\n- Nodes Over 90% Utilization: 21\n- Hottest Node Utilization Percentage: 98.2\n- Coldest Node Utilization Percentage: 47.1\n- Utilization Standard Deviation Percentage: 13.2\n\n#### Rebalance\n- Rebalance Jobs Started: 8\n- Rebalance Jobs Completed: 10\n- Data Moved TB: 372\n- Average Rebalance MBps: 1020\n- Rebalance Queue Depth: 3\n- Skew Index: 1.1\n\n#### Compaction\n- Compactions Run: 1844\n- Compaction CPU Hours: 124.2\n- Write Amplification: 1.5\n- SSTables Compacted: 27760\n- Pending Compactions: 76\n- Average Compaction MB/s: 171\n\n#### IO\n- Read IOPS P95: 209000\n- Write IOPS P95: 111000\n- Read MB/s P95: 3520\n- Write MB/s P95: 1690\n- Disk Busy Percentage P95: 88.3\n- Fsync P95 ms: 12.5\n\n#### Storage Efficiency\n- Replication Factor: 3\n- Erasure Coding Percentage: 26\n- Compression Ratio: 1.81\n- Deduplication Ratio: 1.07\n- Garbage Percentage: 6.6\n- Tombstone Percentage: 3.7\n\n#### Backup Verification\n- Snapshots Taken: 48\n- Snapshots Verified: 48\n- Verify Failures: 0\n- Average Verify Minutes: 36\n- Restore Drills: 1\n- Last Restore RTO Minutes: 47\n\n#### Quota Enforcement\n- Tenants Total: 87\n- Tenants Over Quota: 3\n- Quota Soft Limit Hits: 19\n- Quota Hard Blocks: 2\n- Largest Tenant Used TB: 454\n- New Quota Requests: 4\n\n#### Ingest\n- Ingest TB: 149\n- Egress TB: 126\n- Object Count Delta Million: 50\n- Average Object KB: 93\n- Hot Partition Count: 7\n\n#### Reliability\n- Disk Failures: 0\n- Disk Rebuilds Completed: 0\n- Disk Rebuild Average Hours: 0\n- Node Restarts: 1\n- Unhealthy OSDs: 2\n- Scrub Errors: 12\n\n#### Metadata\n- Metadata DB Size GB: 1080\n- Metadata QPS P95: 65500\n- Metadata Cache Hit Percentage: 90.6\n- Manifest Backlog: 2300\n- Namespace Count: 324\n\n#### Maintenance\n- Firmware Updates: 0\n- Kernel Patches: 1\n- Rack Power Cycles: 0\n- Network Drops: 11\n- Audit Log GB: 77\n\n### Infrastructure\n#### stor-a-09\n- CPU Percentage: 70\n- Memory Percentage: 80\n- Disk Used Percentage: 97\n- Disk Busy Percentage: 88\n- Network In Gbps: 7.3\n- Network Out Gbps: 6.5\n- IO Wait Percentage: 8.3\n\n#### stor-b-16\n- CPU Percentage: 61\n- Memory Percentage: 70\n- Disk Used Percentage: 93\n- Disk Busy Percentage: 84\n- Network In Gbps: 6.1\n- Network Out Gbps: 5.8\n- IO Wait Percentage: 7.0\n\n#### stor-c-15\n- CPU Percentage: 57\n- Memory Percentage: 68\n- Disk Used Percentage: 91\n- Disk Busy Percentage: 79\n- Network In Gbps: 5.0\n- Network Out Gbps: 4.9\n- IO Wait Percentage: 5.5\n\n#### meta-03\n- CPU Percentage: 60\n- Memory Percentage: 87\n- Disk Used Percentage: 82\n- Disk Busy Percentage: 64\n- Network In Gbps: 2.9\n- Network Out Gbps: 2.6\n- IO Wait Percentage: 3.9\n\n### Events\n- Completed aggressive rebalance (10 jobs) and reduced hottest-node utilization from 98.6% to 98.2%; skew index improved to 1.10.\n- Ran weekly restore drill restoring object index plus 500 GB data sample; achieved 47-minute RTO and validated checksum parity.\n- Applied single kernel patch on metadata node; monitored metadata cache hit rate (steady at ~90%).\n- Deep scrubs on previously problematic placement groups completed; scrub errors dropped to 12.\n\n### On Call\n- On Call: Shift: Linh P. \n- Pages: 3\n- Tickets: 7\n- Status: Stable; still operating at high utilization, but hottest-node risk reduced and scrub health improved.",
  "metadata": {
    "episode_type": "distractor",
    "theme": "storage_capacity",
    "theme_index": 1,
    "local_index": 10,
    "scope_id": "cascading_failure_01",
    "layer_name": "distractor_episodes",
    "layer_level": 2,
    "build_fingerprint": {
      "scheme": "synix:build:v1",
      "digest": "627244d584ba0fb65fbf1c2b4c8f282daab56da1cbe5ba1c29eb255b503cfdee",
      "components": {
        "transform": "a88665a5359d5ac5d2c858c77a2a19318c209adeea6fae2b838d79e11f6aba2b",
        "inputs": "c50e2b4719758f72"
      }
    },
    "transform_fingerprint": {
      "scheme": "synix:transform:v2",
      "digest": "a88665a5359d5ac5d2c858c77a2a19318c209adeea6fae2b838d79e11f6aba2b",
      "components": {
        "transform_id": "01137a4997b78f86",
        "source": "c42d9c6282d5331f",
        "model": "1e2ccf75e96d7ee7"
      }
    }
  }
}
{
  "label": "cascading_failure_01_dx_storage_capacity_001",
  "artifact_type": "distractor_episode",
  "artifact_id": "sha256:5c94b19f0a372388d5948fa43eb575bdca0c9699a14301aa3a2bbd672a047b41",
  "input_ids": [
    "sha256:00449ed9d7f8a3240548c2009abc6e3ccafc743718f92388a22452f2b9699234",
    "sha256:8bd255056921270a7048555e132196af832705b4e437017f1abea5378ca40697"
  ],
  "prompt_id": null,
  "model_config": null,
  "created_at": "2026-02-17T11:56:59.923103",
  "content": "## 2026-01-02 Daily Operations Summary\n\n### Metrics\n#### Cluster Capacity\n- Raw TB Total: 9820\n- Raw TB Used: 7134\n- Raw TB Free: 2686\n- Effective TB Total: 6540\n- Effective TB Used: 5128\n- Effective TB Free: 1412\n- Overall Utilization Percentage: 72.6\n\n#### Node Utilization\n- Nodes Total: 120\n- Nodes Over 80% Utilization: 37\n- Nodes Over 90% Utilization: 9\n- Hottest Node Utilization Percentage: 94.2\n- Coldest Node Utilization Percentage: 41.7\n- Utilization Standard Deviation Percentage: 12.4\n\n#### Rebalance\n- Rebalance Jobs Started: 6\n- Rebalance Jobs Completed: 5\n- Data Moved TB: 214\n- Average Rebalance MBps: 860\n- Rebalance Queue Depth: 3\n- Skew Index: 1.18\n\n#### Compaction\n- Compactions Run: 1480\n- Compaction CPU Hours: 96.4\n- Write Amplification: 1.42\n- SSTables Compacted: 22140\n- Pending Compactions: 64\n- Average Compaction MB/s: 182\n\n#### IO\n- Read IOPS P95: 184000\n- Write IOPS P95: 92000\n- Read MB/s P95: 3120\n- Write MB/s P95: 1460\n- Disk Busy Percentage P95: 83.5\n- Fsync P95 ms: 9.4\n\n#### Storage Efficiency\n- Replication Factor: 3\n- Erasure Coding Percentage: 22\n- Compression Ratio: 1.88\n- Deduplication Ratio: 1.12\n- Garbage Percentage: 6.3\n- Tombstone Percentage: 2.7\n\n#### Backup Verification\n- Snapshots Taken: 48\n- Snapshots Verified: 46\n- Verify Failures: 2\n- Average Verify Minutes: 34\n- Restore Drills: 1\n- Last Restore RTO Minutes: 52\n\n#### Quota Enforcement\n- Tenants Total: 84\n- Tenants Over Quota: 3\n- Quota Soft Limit Hits: 11\n- Quota Hard Blocks: 2\n- Largest Tenant Used TB: 412\n- New Quota Requests: 4\n\n#### Ingest\n- Ingest TB: 126\n- Egress TB: 98\n- Object Count Delta M: 42\n- Average Object KB: 96\n- Hot Partition Count: 7\n\n#### Reliability\n- Disk Failures: 1\n- Disk Rebuilds Completed: 1\n- Disk Rebuild Average Hours: 6.8\n- Node Restarts: 2\n- Unhealthy OSDs: 3\n- Scrub Errors: 14\n\n#### Metadata\n- Metadata DB Size GB: 980\n- Metadata QPS P95: 56000\n- Metadata Cache Hit Percentage: 92.4\n- Manifest Backlog: 1800\n- Namespace Count: 310\n\n#### Maintenance\n- Firmware Updates: 4\n- Kernel Patches: 0\n- Rack Power Cycles: 0\n- Network Drops: 12\n- Audit Log GB: 74\n\n### Infrastructure\n#### stor-a-12\n- CPU Percentage: 71\n- Memory Percentage: 78\n- Disk Used Percentage: 93\n- Disk Busy Percentage: 89\n- Network In Gbps: 7.4\n- Network Out Gbps: 6.1\n- IO Wait Percentage: 8.2\n\n#### stor-b-07\n- CPU Percentage: 54\n- Memory Percentage: 66\n- Disk Used Percentage: 88\n- Disk Busy Percentage: 77\n- Network In Gbps: 5.2\n- Network Out Gbps: 4.8\n- IO Wait Percentage: 5.1\n\n#### stor-c-19\n- CPU Percentage: 62\n- Memory Percentage: 73\n- Disk Used Percentage: 91\n- Disk Busy Percentage: 86\n- Network In Gbps: 6.8\n- Network Out Gbps: 6.5\n- IO Wait Percentage: 7.6\n\n#### meta-02\n- CPU Percentage: 48\n- Memory Percentage: 81\n- Disk Used Percentage: 74\n- Disk Busy Percentage: 52\n- Network In Gbps: 2.1\n- Network Out Gbps: 1.9\n- IO Wait Percentage: 2.4\n\n### Events\n- Triggered scheduled rebalance to reduce rack-level skew after adding 4 replacement disks in rack R12; moved 62 TB overnight.\n- Two snapshot verification failures traced to stale credentials on verifier worker; rotated keys and re-ran checks successfully.\n- One disk in stor-a-12 showed rising media errors; proactively replaced and completed rebuild in 6.8 hours.\n- Quota hard-block applied to tenant 'analytics-42' after exceeding 15 TB over allotment; coordinated temporary burst allowance and clean-up plan.\n\n### On Call\n- Shift: Priya S.\n- Pages: 3\n- Tickets: 7\n- Status: Stable after disk replacement and verifier key rotation; monitoring hottest nodes >90% and compaction backlog.",
  "metadata": {
    "episode_type": "distractor",
    "theme": "storage_capacity",
    "theme_index": 1,
    "local_index": 1,
    "scope_id": "cascading_failure_01",
    "layer_name": "distractor_episodes",
    "layer_level": 2,
    "build_fingerprint": {
      "scheme": "synix:build:v1",
      "digest": "627244d584ba0fb65fbf1c2b4c8f282daab56da1cbe5ba1c29eb255b503cfdee",
      "components": {
        "transform": "a88665a5359d5ac5d2c858c77a2a19318c209adeea6fae2b838d79e11f6aba2b",
        "inputs": "c50e2b4719758f72"
      }
    },
    "transform_fingerprint": {
      "scheme": "synix:transform:v2",
      "digest": "a88665a5359d5ac5d2c858c77a2a19318c209adeea6fae2b838d79e11f6aba2b",
      "components": {
        "transform_id": "01137a4997b78f86",
        "source": "c42d9c6282d5331f",
        "model": "1e2ccf75e96d7ee7"
      }
    }
  }
}